# ðŸŽ‰ LLM Integrated! OpenRouter + MCP + FastAPI

## What's New

âœ… **Intelligent LLM Agent** - Uses OpenRouter's z-ai/glm-4.5-air:free (free!)  
âœ… **Automatic Tool Calling** - LLM decides when and which tools to use  
âœ… **Agentic Loop** - Supports multi-step reasoning with tools  
âœ… **Full Conversation** - Maintains context across multiple turns  
âœ… **Works with HTML UI** - Same beautiful interface  

## Quick Start

```powershell
# 1. Make sure your .env file has OPENROUTER_API_KEY
# (Already configured from earlier)

# 2. Start the server
python run_fixed.py

# 3. Open browser
start http://localhost:8000

# 4. Connect and chat!
```

## How It Works

### The Magic Flow:

1. **User** â†’ Sends message via HTML UI
2. **FastAPI** â†’ Receives request
3. **LLM Agent** â†’ Analyzes message with GLM-4-Flash
4. **LLM decides** â†’ "I need to call list_tables tool"
5. **MCP Client** â†’ Executes the tool via SQLite server
6. **Tool Result** â†’ Returns data to LLM
7. **LLM thinks** â†’ "Now I can answer the user"
8. **Response** â†’ Beautiful natural language answer!

### Architecture:

```
User (HTML) 
    â†“
FastAPI Server
    â†“
LLM Agent (llm_integration.py)
    â†“
OpenRouter API (GLM-4-Flash)
    â†“
MCP Client (mcp_client_fixed.py)
    â†“
SQLite MCP Server (sqlite_mcp_fastmcp.py)
    â†“
SQLite Database
```

## Example Conversations

### Example 1: Simple Query

**User:** "What tables are in the database?"

**LLM Thinks:** ðŸ¤” *I need to call list_tables*

**Tool Call:** `list_tables()`

**Result:** `["users", "products", "orders"]`

**LLM Response:** "The database contains three tables: users, products, and orders."

---

### Example 2: Multi-Step Reasoning

**User:** "Tell me about the users table structure and show me 3 users"

**LLM Thinks:** ðŸ¤” *I need to call two tools*

**Tool Call 1:** `describe_table(table_name="users")`

**Result:** `[{"column": "id", "type": "INTEGER"}, ...]`

**Tool Call 2:** `execute_query(query="SELECT * FROM users LIMIT 3")`

**Result:** `[{"id": 1, "name": "Alice"}, ...]`

**LLM Response:** "The users table has 4 columns: id (INTEGER), name (TEXT), email (TEXT), and created_at (TIMESTAMP). Here are 3 example users: Alice (alice@example.com), Bob (bob@example.com), and Carol (carol@example.com)."

---

### Example 3: Complex Query

**User:** "How many users do we have and what's the most recent user?"

**LLM Thinks:** ðŸ¤” *Need to run SQL*

**Tool Call:** `execute_query(query="SELECT COUNT(*) as total, MAX(created_at) as latest FROM users")`

**Result:** `[{"total": 25, "latest": "2025-01-10"}]`

**LLM Response:** "You have 25 users in the database. The most recent user was added on January 10, 2025."

---

## Available Models

The system supports multiple OpenRouter models:

1. **z-ai/glm-4.5-air:free** (Default, FREE!)
   - Fast responses
   - Good tool calling
   - Free tier available

2. **anthropic/claude-3.5-sonnet**
   - Excellent reasoning
   - Best tool calling
   - Paid model

3. **openai/gpt-4-turbo**
   - Strong performance
   - Reliable tool use
   - Paid model

4. **google/gemini-pro**
   - Good general purpose
   - Fast responses
   - Paid model

## Configuration

### Using Different Models

In the HTML UI:
1. Select different model from dropdown before connecting
2. Each model has different strengths!

Via API:
```bash
curl -X POST http://localhost:8000/api/connect \
  -H "Content-Type: application/json" \
  -d '{
    "server_name": "SQLite",
    "model": "anthropic/claude-3.5-sonnet"
  }'
```

### Environment Variables

Your `.env` file should have:
```
OPENROUTER_API_KEY=your-key-here
DEFAULT_MODEL=z-ai/glm-4.5-air:free
```

## Features

### âœ… Intelligent Tool Selection

The LLM automatically determines:
- **When** to use tools (vs just answering from knowledge)
- **Which** tools to use (from all 8 available)
- **How** to combine multiple tools for complex queries
- **What** arguments to pass to each tool

### âœ… Agentic Loop

Supports multi-step reasoning:
1. User asks complex question
2. LLM calls tool #1
3. Analyzes result
4. Calls tool #2 with refined query
5. Synthesizes final answer

Up to **10 iterations** for complex tasks!

### âœ… Conversation Memory

Maintains full conversation history:
- Remembers previous questions
- Refers back to earlier tool results
- Builds on previous context

Clear with: "Clear Chat" button

### âœ… All MCP Tools Available

The LLM can use all 8 SQLite tools:

1. **list_tables** - List database tables
2. **describe_table** - Get table schema
3. **execute_query** - Run any SQL query
4. **get_database_info** - Database metadata
5. **create_user** - Add new user
6. **list_users** - Show all users
7. **update_user** - Modify user
8. **delete_user** - Remove user

## Testing

### Test 1: Basic Tool Call

```
User: "List all tables"
Expected: Uses list_tables tool, shows table names
```

### Test 2: Complex Query

```
User: "Show me the structure of the users table and count how many users we have"
Expected: Uses describe_table AND execute_query
```

### Test 3: Natural Language

```
User: "I need to understand the database schema"
Expected: Uses multiple tools intelligently
```

### Test 4: Multi-Turn Conversation

```
User: "What tables exist?"
AI: "There are users, products, and orders tables"
User: "Tell me more about the users table"
Expected: Remembers previous context, provides detailed info
```

## API Usage

### Python Example

```python
import requests

API = "http://localhost:8000"

# Connect
requests.post(f"{API}/api/connect", json={
    "server_name": "SQLite",
    "model": "z-ai/glm-4.5-air:free"
})

# Chat
response = requests.post(f"{API}/api/chat", json={
    "message": "What tables are in the database and how many rows in each?"
})

result = response.json()
print(f"AI: {result['response']}")
print(f"Tools used: {len(result['tool_calls'])}")

for tool in result['tool_calls']:
    print(f"  - {tool['tool_name']}: {tool['duration_ms']}ms")
```

### JavaScript Example

```javascript
// Connect
await fetch('http://localhost:8000/api/connect', {
    method: 'POST',
    headers: {'Content-Type': 'application/json'},
    body: JSON.stringify({
        server_name: 'SQLite',
        model: 'z-ai/glm-4.5-air:free'
    })
});

// Chat
const response = await fetch('http://localhost:8000/api/chat', {
    method: 'POST',
    headers: {'Content-Type': 'application/json'},
    body: JSON.stringify({
        message: 'Analyze the database structure'
    })
});

const data = await response.json();
console.log('AI:', data.response);
console.log('Tools:', data.tool_calls);
```

## Troubleshooting

### Issue: "Connection failed"

**Check:**
1. OPENROUTER_API_KEY in .env file
2. API key is valid
3. Internet connection works

### Issue: "No tool calls"

**Possible reasons:**
1. LLM thinks it doesn't need tools (try more specific question)
2. Question can be answered from general knowledge
3. Try: "Use the available tools to..." in your prompt

### Issue: "Tool execution failed"

**Check:**
1. SQLite server is connected
2. Database file exists
3. SQL query is valid (if using execute_query)

### Issue: "Slow responses"

**Normal behavior:**
- First response: 3-5 seconds (tool calling)
- Follow-up: 2-3 seconds
- Complex queries: 5-10 seconds

**To speed up:**
- Use faster model (glm-4-flash is already fastest)
- Simplify question
- Check API rate limits

## Performance

### Typical Response Times

- **Simple query** (1 tool): 2-4 seconds
- **Medium complexity** (2-3 tools): 4-8 seconds
- **Complex analysis** (4+ tools): 8-15 seconds

### Token Usage

- **z-ai/glm-4.5-air:free**: ~500-2000 tokens per request
- **Tool descriptions**: ~1000 tokens overhead
- **Conversation history**: Grows with each turn

## Production Tips

### 1. Add System Prompt

Customize LLM behavior in `llm_integration.py`:

```python
self.conversation_history = [{
    "role": "system",
    "content": "You are a helpful database assistant. Always use tools when asked about data. Be concise but informative."
}]
```

### 2. Limit Tool Selection

For faster responses, only expose relevant tools:

```python
# In get_mcp_tools_for_openrouter()
# Filter tools based on user permissions or context
```

### 3. Add Streaming

For better UX, stream LLM responses:

```python
# Use OpenRouter's streaming endpoint
# Send chunks to frontend via WebSocket
```

### 4. Cache Common Queries

Store frequent query results:

```python
# Add Redis cache for common tool results
# Reduce API calls and tool executions
```

## Summary

ðŸŽ‰ **You now have a fully functional AI agent!**

**Components:**
- âœ… FastAPI backend
- âœ… OpenRouter LLM (GLM-4-Flash)
- âœ… Intelligent tool calling
- âœ… MCP protocol integration
- âœ… SQLite database tools
- âœ… Beautiful HTML frontend

**Capabilities:**
- ðŸ§  Natural language to database queries
- ðŸ”§ Automatic tool selection
- ðŸ”„ Multi-step reasoning
- ðŸ’¬ Conversation memory
- âš¡ Fast responses

**Usage:**
```powershell
python run_fixed.py
# Open http://localhost:8000
# Connect to SQLite
# Ask anything!
```

**Example questions to try:**
- "What's in this database?"
- "Show me 5 users"
- "Create a user named John with email john@test.com"
- "How many products cost more than $50?"
- "Analyze the database structure and give me insights"

**That's it! You have a complete AI-powered database assistant!** ðŸš€

